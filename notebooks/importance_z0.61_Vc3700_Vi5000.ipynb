{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance weights\n",
    "\n",
    "In this notebook we compute the importance weights using the `PyBird` likelihoods calculated in `pybird_importance_likes.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matryoshka.emulator as MatEmu\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "import zeus\n",
    "from scipy.interpolate import interp1d\n",
    "import corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with most of the other notebooks in this repo we start by specifying the repo location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_repo = \"/Users/jamie/Desktop/GitHubProjects/matryoshka_II_paper/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PyBird` likelihoods have been calculated for samples from an `EFTEMU` posterior with $V_s^{1/3}=3700\\ \\mathrm{Mpc}\\ h^{-1}$, but using a covariance with $V_s^{1/3}=5000\\ \\mathrm{Mpc}\\ h^{-1}$. We do this as the posterior with the smaller $V_s$ will be inflated, mitigating the risk of loosing the tails of the `PyBird` posterior.\n",
    "\n",
    "To calculate the importance weights we need to calculate the `EFTEMU` likelihood for the same samples. So we start by loading the samples, along with the `PyBird` likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = []\n",
    "pybird_likes = []\n",
    "for i in range(6):\n",
    "    chain.append(np.load(path_to_repo+\"results/chain--EFTEMU_z-0.61_V-3700_kmin-def_kmax-def_{i}.npy\".format(i=i)))\n",
    "    pybird_likes.append(np.load(path_to_repo+\"results/pybird_likes--EFTEMU_z-0.61_Vc-3700_Vi-5000_kmin-def_kmax-def_{i}.npy\".format(i=i)))\n",
    "chain = np.vstack(chain)\n",
    "pybird_likes = np.concatenate(pybird_likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the mocks and covariance with $V_s^{1/3}=3700\\ \\mathrm{Mpc}\\ h^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "P0_true = np.load(path_to_repo+\"data/P18/z0.61/poles/P0_P18--z-0.61_optiresum-False.npy\")[1]\n",
    "P2_true = np.load(path_to_repo+\"data/P18/z0.61/poles/P2_P18--z-0.61_optiresum-False.npy\")[1]\n",
    "klin = np.load(path_to_repo+\"data/P18/z0.61/poles/P2_P18--z-0.61_optiresum-False.npy\")[0]\n",
    "cov = np.load(path_to_repo+\"data/P18/z0.61/covs/cov_P18--z-0.61_Vs-3700.npy\")\n",
    "icov = np.linalg.inv(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the truths,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_true = np.array([0.11933, 0.02242, 0.6766, 3.047, 0.9665])\n",
    "bs_CMASS = np.array([2.22, 1.2, 0.1, 0.0, 0.4, -7.7, 0., 0., 0., -3.7])\n",
    "fb_true = cosmo_true[1]/(cosmo_true[0]+cosmo_true[1])\n",
    "ng = 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and initalise the emulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 12:43:45.978678: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "P0_emu = MatEmu.EFT(multipole=0, version='EFTv2', redshift=0.61)\n",
    "P2_emu = MatEmu.EFT(multipole=2, version='EFTv2', redshift=0.61)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we define the `log_like()` and `fix_params()` functions. For some more details about these functions see `mcmc_z0.61_v3700_EFTEMU.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like(theta, kobs, obs, icov):\n",
    "    # Oc, Ob, h, As, ns\n",
    "    cosmo = theta[:,:5]\n",
    "    # b1, c2, b3, c4, cct, cr1, cr2\n",
    "    bias = theta[:,5:12]\n",
    "    # ce1, cmono, cquad\n",
    "    stoch = theta[:,12:]\n",
    "    \n",
    "    \n",
    "    c2 = np.copy(bias[:,1])\n",
    "    c4 = np.copy(bias[:,3])\n",
    "    \n",
    "    bias[:,1] = (c2+c4)/np.sqrt(2)\n",
    "    bias[:,3] = (c2-c4)/np.sqrt(2)\n",
    "            \n",
    "    P0_pred = P0_emu.emu_predict(cosmo, bias, stochastic=stoch, ng=ng)\n",
    "    P2_pred = P2_emu.emu_predict(cosmo, bias, stochastic=stoch, ng=ng)\n",
    "        \n",
    "    preds = np.hstack([interp1d(MatEmu.kbird[:39], P0_pred)(kobs), \n",
    "                           interp1d(MatEmu.kbird[:39], P2_pred)(kobs)])\n",
    "    \n",
    "    res = preds-obs\n",
    "    \n",
    "    return -0.5*np.einsum(\"nj,ij,in->n\", res, icov, res.T)\n",
    "\n",
    "def fix_params(theta, fix_val, fb):\n",
    "    \n",
    "    # Define indicies of parameters that vary.\n",
    "    var_id = np.array([0,2,3,5,6,7,9,10,12,14])\n",
    "    \n",
    "    # Define indicies of fixed params.\n",
    "    fix_id = np.array([4,8,11,13])\n",
    "    \n",
    "    fix_theta = np.zeros((theta.shape[0], 15))\n",
    "    fix_theta[:,var_id] = theta\n",
    "    fix_theta[:,fix_id] = np.vstack(theta.shape[0]*[fix_val])\n",
    "    \n",
    "    # Comput w_b from baryon fraction and w_c\n",
    "    fix_theta[:,1] = -fb*theta[:,0]/(fb-1)\n",
    "    \n",
    "    return fix_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fix all the relevant parameters,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = np.array([cosmo_true[-1], 0., 0., 0.])\n",
    "fixed_chain = fix_params(chain, fixed_params, fb_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and calculate the `EFTEMU` likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFTEMU_likes = log_like(fixed_chain, klin, np.concatenate([P0_true, P2_true]), icov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The importance weights are given by,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$I_i = \\frac{P(\\theta_i)\\mathcal{L}_\\texttt{PyBird}(P'|\\theta_i)}{P(\\theta_i)\\mathcal{L}_\\texttt{EFTEMU}(P'|\\theta_i)}\\ ,$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $\\mathcal{L}_\\texttt{PyBird}(P'|\\theta_i)$ and $\\mathcal{L}_\\texttt{EFTEMU}(P'|\\theta_i)$ being the likelihods for `PyBird` and the `EFTEMU` respectively. Remeber that $V_s^{1/3}=5000\\ \\mathrm{Mpc}\\ h^{-1}$ in the `PyBird` likelihood and $V_s^{1/3}=3700\\ \\mathrm{Mpc}\\ h^{-1}$ in the `EFTEMU` likelihood. $P(\\theta_i)$ is the prior, but as it is idenical for both `PyBird` and the `EFTEMU` the importance weight $I_i$ reduces to a ratio of the likelihoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as we have actually been computing the log-likelihood we first need to exponentiate. To improve the numerical stability we subtract the mean `EFTEMU` log-likelihood from both the `PyBird` and `EFTEMU` log-likelihoods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.exp(pybird_likes-EFTEMU_likes.mean())/np.exp(EFTEMU_likes-EFTEMU_likes.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the _effective sample size_ (ESS) from these weights,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathrm{ESS} = \\frac{\\left(\\sum_i I_i\\right)^2}{\\sum_i I_i^2}\\ .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817.4200934398144, 0.06396088368073666)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESS = np.sum(ratio)**2/np.sum(ratio**2)\n",
    "ESS, ESS/chain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_to_repo+\"results/weights--EFTEMU_z-0.61_Vc-3700_Vi-5000_kmin-def_kmax-def_all.npy\", ratio/ratio.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matryoshka",
   "language": "python",
   "name": "matryoshka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
